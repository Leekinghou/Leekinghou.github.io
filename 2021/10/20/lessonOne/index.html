<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>李宏毅2021年(春)深度学习 作业一 | lijinhao's blog</title><meta name="keywords" content="ML"><meta name="author" content="lijinhao"><meta name="copyright" content="lijinhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="监督学习"><meta property="og:type" content="article"><meta property="og:title" content="李宏毅2021年(春)深度学习 作业一"><meta property="og:url" content="https://leekinghou.github.io/2021/10/20/lessonOne/index.html"><meta property="og:site_name" content="lijinhao&#39;s blog"><meta property="og:description" content="监督学习"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://inews.gtimg.com/newsapp_ls/0/14146721068/0"><meta property="article:published_time" content="2021-10-19T16:00:00.000Z"><meta property="article:modified_time" content="2021-11-06T07:32:42.028Z"><meta property="article:author" content="lijinhao"><meta property="article:tag" content="Machine Learning"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://inews.gtimg.com/newsapp_ls/0/14146721068/0"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://leekinghou.github.io/2021/10/20/lessonOne/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:void 0,translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"簡"},noticeOutdate:void 0,highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1},copy:{success:"Copy successfully",error:"Copy error",noSupport:"The browser does not support"},relativeDate:{homepage:!1,post:!1},runtime:"days",date_suffix:{just:"Just",min:"minutes ago",hour:"hours ago",day:"days ago",month:"months ago"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,source:{jQuery:"https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js",justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js",css:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css"},fancybox:{js:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js",css:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isanchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"李宏毅2021年(春)深度学习 作业一",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2021-11-06 15:32:42"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){if(0===o)return;const n=864e5*o,a={value:t,expiry:(new Date).getTime()+n};localStorage.setItem(e,JSON.stringify(a))},get:function(e){const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!((new Date).getTime()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=e=>new Promise((t,o)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=o,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,t())},document.head.appendChild(n)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));GLOBAL_CONFIG_SITE.isHome&&/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom@1.0.0.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/portrait.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">27</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i> <span>清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i> <span>音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i> <span>照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i> <span>电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">lijinhao's blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i> <span>清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i> <span>音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i> <span>照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i> <span>电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">李宏毅2021年(春)深度学习 作业一</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-10-19T16:00:00.000Z" title="Created 2021-10-20 00:00:00">2021-10-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-11-06T07:32:42.028Z" title="Updated 2021-11-06 15:32:42">2021-11-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="李宏毅2021年(春)深度学习 作业一"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div><article class="post-content" id="article-container"><p><img src="https://inews.gtimg.com/newsapp_ls/0/14091523188/0"></p><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tr_path = <span class="string">&#x27;covid.train.csv&#x27;</span>  <span class="comment"># path to training data</span></span><br><span class="line">tt_path = <span class="string">&#x27;covid.test.csv&#x27;</span>   <span class="comment"># path to testing data</span></span><br><span class="line"></span><br><span class="line">!gdown --<span class="built_in">id</span> <span class="string">&#x27;19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF&#x27;</span> --output covid.train.csv</span><br><span class="line">!gdown --<span class="built_in">id</span> <span class="string">&#x27;1CE240jLm2npU-tdz81-oVKEF3T2yfT1O&#x27;</span> --output covid.test.csv</span><br></pre></td></tr></table></figure><pre><code>Downloading...
From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF
To: /Users/baikal/machineLearning/lessonOne/covid.train.csv
100%|███████████████████████████████████████| 2.00M/2.00M [00:17&lt;00:00, 115kB/s]
Downloading...
From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O
To: /Users/baikal/machineLearning/lessonOne/covid.test.csv
100%|█████████████████████████████████████████| 651k/651k [00:05&lt;00:00, 125kB/s]
</code></pre><p>需要使用google下载工具下载google drive上的文件，安装方法：<br><code>pip install gdown</code></p><h2 id="查看数据集"><a href="#查看数据集" class="headerlink" title="查看数据集"></a>查看数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下面三个包是新增的</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> pprint <span class="keyword">as</span> pp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取训练数据</span></span><br><span class="line">data_tr = pd.read_csv(tr_path)</span><br><span class="line"><span class="comment"># 读取测试数据</span></span><br><span class="line">data_tt = pd.read_csv(tt_path)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取训练数据前5行</span></span><br><span class="line">data_tr.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><p></p><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>AL</th><th>AK</th><th>AZ</th><th>AR</th><th>CA</th><th>CO</th><th>CT</th><th>FL</th><th>GA</th><th>ID</th><th>...</th><th>restaurant.2</th><th>spent_time.2</th><th>large_event.2</th><th>public_transit.2</th><th>anxious.2</th><th>depressed.2</th><th>felt_isolated.2</th><th>worried_become_ill.2</th><th>worried_finances.2</th><th>tested_positive.2</th></tr></thead><tbody><tr><th>0</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>23.812411</td><td>43.430423</td><td>16.151527</td><td>1.602635</td><td>15.409449</td><td>12.088688</td><td>16.702086</td><td>53.991549</td><td>43.604229</td><td>20.704935</td></tr><tr><th>1</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>23.682974</td><td>43.196313</td><td>16.123386</td><td>1.641863</td><td>15.230063</td><td>11.809047</td><td>16.506973</td><td>54.185521</td><td>42.665766</td><td>21.292911</td></tr><tr><th>2</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>23.593983</td><td>43.362200</td><td>16.159971</td><td>1.677523</td><td>15.717207</td><td>12.355918</td><td>16.273294</td><td>53.637069</td><td>42.972417</td><td>21.166656</td></tr><tr><th>3</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>22.576992</td><td>42.954574</td><td>15.544373</td><td>1.578030</td><td>15.295650</td><td>12.218123</td><td>16.045504</td><td>52.446223</td><td>42.907472</td><td>19.896607</td></tr><tr><th>4</th><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>22.091433</td><td>43.290957</td><td>15.214655</td><td>1.641667</td><td>14.778802</td><td>12.417256</td><td>16.134238</td><td>52.560315</td><td>43.321985</td><td>20.178428</td></tr></tbody></table><p>5 rows × 94 columns</p></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取测试数据前5行</span></span><br><span class="line">data_tt.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><p></p><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>id</th><th>AL</th><th>AK</th><th>AZ</th><th>AR</th><th>CA</th><th>CO</th><th>CT</th><th>FL</th><th>GA</th><th>...</th><th>shop.2</th><th>restaurant.2</th><th>spent_time.2</th><th>large_event.2</th><th>public_transit.2</th><th>anxious.2</th><th>depressed.2</th><th>felt_isolated.2</th><th>worried_become_ill.2</th><th>worried_finances.2</th></tr></thead><tbody><tr><th>0</th><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>52.071090</td><td>8.624001</td><td>29.374792</td><td>5.391413</td><td>2.754804</td><td>19.695098</td><td>13.685645</td><td>24.747837</td><td>66.194950</td><td>44.873473</td></tr><tr><th>1</th><td>1</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>58.742461</td><td>21.720187</td><td>41.375784</td><td>9.450179</td><td>3.150088</td><td>22.075715</td><td>17.302077</td><td>23.559622</td><td>57.015009</td><td>38.372829</td></tr><tr><th>2</th><td>2</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>59.109045</td><td>20.123959</td><td>40.072556</td><td>8.781522</td><td>2.888209</td><td>23.920870</td><td>18.342506</td><td>24.993341</td><td>55.291498</td><td>38.907257</td></tr><tr><th>3</th><td>3</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>55.442267</td><td>16.083529</td><td>36.977612</td><td>5.199286</td><td>2.575347</td><td>21.073800</td><td>12.087171</td><td>18.608723</td><td>67.036197</td><td>43.142779</td></tr><tr><th>4</th><td>4</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>...</td><td>60.588783</td><td>19.503010</td><td>42.631236</td><td>11.549771</td><td>8.530551</td><td>15.896575</td><td>11.781634</td><td>15.065228</td><td>61.196518</td><td>43.574676</td></tr></tbody></table><p>5 rows × 94 columns</p></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看有多少列特征</span></span><br><span class="line">data_tr.columns</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;id&#39;, &#39;AL&#39;, &#39;AK&#39;, &#39;AZ&#39;, &#39;AR&#39;, &#39;CA&#39;, &#39;CO&#39;, &#39;CT&#39;, &#39;FL&#39;, &#39;GA&#39;, &#39;ID&#39;, &#39;IL&#39;,
       &#39;IN&#39;, &#39;IA&#39;, &#39;KS&#39;, &#39;KY&#39;, &#39;LA&#39;, &#39;MD&#39;, &#39;MA&#39;, &#39;MI&#39;, &#39;MN&#39;, &#39;MS&#39;, &#39;MO&#39;, &#39;NE&#39;,
       &#39;NV&#39;, &#39;NJ&#39;, &#39;NM&#39;, &#39;NY&#39;, &#39;NC&#39;, &#39;OH&#39;, &#39;OK&#39;, &#39;OR&#39;, &#39;PA&#39;, &#39;RI&#39;, &#39;SC&#39;, &#39;TX&#39;,
       &#39;UT&#39;, &#39;VA&#39;, &#39;WA&#39;, &#39;WV&#39;, &#39;WI&#39;, &#39;cli&#39;, &#39;ili&#39;, &#39;hh_cmnty_cli&#39;,
       &#39;nohh_cmnty_cli&#39;, &#39;wearing_mask&#39;, &#39;travel_outside_state&#39;,
       &#39;work_outside_home&#39;, &#39;shop&#39;, &#39;restaurant&#39;, &#39;spent_time&#39;, &#39;large_event&#39;,
       &#39;public_transit&#39;, &#39;anxious&#39;, &#39;depressed&#39;, &#39;felt_isolated&#39;,
       &#39;worried_become_ill&#39;, &#39;worried_finances&#39;, &#39;tested_positive&#39;, &#39;cli.1&#39;,
       &#39;ili.1&#39;, &#39;hh_cmnty_cli.1&#39;, &#39;nohh_cmnty_cli.1&#39;, &#39;wearing_mask.1&#39;,
       &#39;travel_outside_state.1&#39;, &#39;work_outside_home.1&#39;, &#39;shop.1&#39;,
       &#39;restaurant.1&#39;, &#39;spent_time.1&#39;, &#39;large_event.1&#39;, &#39;public_transit.1&#39;,
       &#39;anxious.1&#39;, &#39;depressed.1&#39;, &#39;felt_isolated.1&#39;, &#39;worried_become_ill.1&#39;,
       &#39;worried_finances.1&#39;, &#39;tested_positive.1&#39;, &#39;cli.2&#39;, &#39;ili.2&#39;,
       &#39;hh_cmnty_cli.2&#39;, &#39;nohh_cmnty_cli.2&#39;, &#39;wearing_mask.2&#39;,
       &#39;travel_outside_state.2&#39;, &#39;work_outside_home.2&#39;, &#39;shop.2&#39;,
       &#39;restaurant.2&#39;, &#39;spent_time.2&#39;, &#39;large_event.2&#39;, &#39;public_transit.2&#39;,
       &#39;anxious.2&#39;, &#39;depressed.2&#39;, &#39;felt_isolated.2&#39;, &#39;worried_become_ill.2&#39;,
       &#39;worried_finances.2&#39;, &#39;tested_positive.2&#39;],
      dtype=&#39;object&#39;)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># id列用不到，去除</span></span><br><span class="line">data_tr.drop([<span class="string">&#x27;id&#x27;</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">data_tt.drop([<span class="string">&#x27;id&#x27;</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 取特征列</span></span><br><span class="line">cols = <span class="built_in">list</span>(data_tr.columns)</span><br><span class="line">pp.pprint(data_tr.columns)</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;AL&#39;, &#39;AK&#39;, &#39;AZ&#39;, &#39;AR&#39;, &#39;CA&#39;, &#39;CO&#39;, &#39;CT&#39;, &#39;FL&#39;, &#39;GA&#39;, &#39;ID&#39;, &#39;IL&#39;, &#39;IN&#39;,
       &#39;IA&#39;, &#39;KS&#39;, &#39;KY&#39;, &#39;LA&#39;, &#39;MD&#39;, &#39;MA&#39;, &#39;MI&#39;, &#39;MN&#39;, &#39;MS&#39;, &#39;MO&#39;, &#39;NE&#39;, &#39;NV&#39;,
       &#39;NJ&#39;, &#39;NM&#39;, &#39;NY&#39;, &#39;NC&#39;, &#39;OH&#39;, &#39;OK&#39;, &#39;OR&#39;, &#39;PA&#39;, &#39;RI&#39;, &#39;SC&#39;, &#39;TX&#39;, &#39;UT&#39;,
       &#39;VA&#39;, &#39;WA&#39;, &#39;WV&#39;, &#39;WI&#39;, &#39;cli&#39;, &#39;ili&#39;, &#39;hh_cmnty_cli&#39;, &#39;nohh_cmnty_cli&#39;,
       &#39;wearing_mask&#39;, &#39;travel_outside_state&#39;, &#39;work_outside_home&#39;, &#39;shop&#39;,
       &#39;restaurant&#39;, &#39;spent_time&#39;, &#39;large_event&#39;, &#39;public_transit&#39;, &#39;anxious&#39;,
       &#39;depressed&#39;, &#39;felt_isolated&#39;, &#39;worried_become_ill&#39;, &#39;worried_finances&#39;,
       &#39;tested_positive&#39;, &#39;cli.1&#39;, &#39;ili.1&#39;, &#39;hh_cmnty_cli.1&#39;,
       &#39;nohh_cmnty_cli.1&#39;, &#39;wearing_mask.1&#39;, &#39;travel_outside_state.1&#39;,
       &#39;work_outside_home.1&#39;, &#39;shop.1&#39;, &#39;restaurant.1&#39;, &#39;spent_time.1&#39;,
       &#39;large_event.1&#39;, &#39;public_transit.1&#39;, &#39;anxious.1&#39;, &#39;depressed.1&#39;,
       &#39;felt_isolated.1&#39;, &#39;worried_become_ill.1&#39;, &#39;worried_finances.1&#39;,
       &#39;tested_positive.1&#39;, &#39;cli.2&#39;, &#39;ili.2&#39;, &#39;hh_cmnty_cli.2&#39;,
       &#39;nohh_cmnty_cli.2&#39;, &#39;wearing_mask.2&#39;, &#39;travel_outside_state.2&#39;,
       &#39;work_outside_home.2&#39;, &#39;shop.2&#39;, &#39;restaurant.2&#39;, &#39;spent_time.2&#39;,
       &#39;large_event.2&#39;, &#39;public_transit.2&#39;, &#39;anxious.2&#39;, &#39;depressed.2&#39;,
       &#39;felt_isolated.2&#39;, &#39;worried_become_ill.2&#39;, &#39;worried_finances.2&#39;,
       &#39;tested_positive.2&#39;],
      dtype=&#39;object&#39;)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 看每列数据类型和大小</span></span><br><span class="line">pp.pprint(data_tr.info()) </span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 2700 entries, 0 to 2699
Data columns (total 94 columns):
 #   Column                  Non-Null Count  Dtype  
---  ------                  --------------  -----  
 0   AL                      2700 non-null   float64
 1   AK                      2700 non-null   float64
 2   AZ                      2700 non-null   float64
 3   AR                      2700 non-null   float64
 4   CA                      2700 non-null   float64
 5   CO                      2700 non-null   float64
 6   CT                      2700 non-null   float64
 7   FL                      2700 non-null   float64
 8   GA                      2700 non-null   float64
 9   ID                      2700 non-null   float64
 10  IL                      2700 non-null   float64
 11  IN                      2700 non-null   float64
 12  IA                      2700 non-null   float64
 13  KS                      2700 non-null   float64
 14  KY                      2700 non-null   float64
 15  LA                      2700 non-null   float64
 16  MD                      2700 non-null   float64
 17  MA                      2700 non-null   float64
 18  MI                      2700 non-null   float64
 19  MN                      2700 non-null   float64
 20  MS                      2700 non-null   float64
 21  MO                      2700 non-null   float64
 22  NE                      2700 non-null   float64
 23  NV                      2700 non-null   float64
 24  NJ                      2700 non-null   float64
 25  NM                      2700 non-null   float64
 26  NY                      2700 non-null   float64
 27  NC                      2700 non-null   float64
 28  OH                      2700 non-null   float64
 29  OK                      2700 non-null   float64
 30  OR                      2700 non-null   float64
 31  PA                      2700 non-null   float64
 32  RI                      2700 non-null   float64
 33  SC                      2700 non-null   float64
 34  TX                      2700 non-null   float64
 35  UT                      2700 non-null   float64
 36  VA                      2700 non-null   float64
 37  WA                      2700 non-null   float64
 38  WV                      2700 non-null   float64
 39  WI                      2700 non-null   float64
 40  cli                     2700 non-null   float64
 41  ili                     2700 non-null   float64
 42  hh_cmnty_cli            2700 non-null   float64
 43  nohh_cmnty_cli          2700 non-null   float64
 44  wearing_mask            2700 non-null   float64
 45  travel_outside_state    2700 non-null   float64
 46  work_outside_home       2700 non-null   float64
 47  shop                    2700 non-null   float64
 48  restaurant              2700 non-null   float64
 49  spent_time              2700 non-null   float64
 50  large_event             2700 non-null   float64
 51  public_transit          2700 non-null   float64
 52  anxious                 2700 non-null   float64
 53  depressed               2700 non-null   float64
 54  felt_isolated           2700 non-null   float64
 55  worried_become_ill      2700 non-null   float64
 56  worried_finances        2700 non-null   float64
 57  tested_positive         2700 non-null   float64
 58  cli.1                   2700 non-null   float64
 59  ili.1                   2700 non-null   float64
 60  hh_cmnty_cli.1          2700 non-null   float64
 61  nohh_cmnty_cli.1        2700 non-null   float64
 62  wearing_mask.1          2700 non-null   float64
 63  travel_outside_state.1  2700 non-null   float64
 64  work_outside_home.1     2700 non-null   float64
 65  shop.1                  2700 non-null   float64
 66  restaurant.1            2700 non-null   float64
 67  spent_time.1            2700 non-null   float64
 68  large_event.1           2700 non-null   float64
 69  public_transit.1        2700 non-null   float64
 70  anxious.1               2700 non-null   float64
 71  depressed.1             2700 non-null   float64
 72  felt_isolated.1         2700 non-null   float64
 73  worried_become_ill.1    2700 non-null   float64
 74  worried_finances.1      2700 non-null   float64
 75  tested_positive.1       2700 non-null   float64
 76  cli.2                   2700 non-null   float64
 77  ili.2                   2700 non-null   float64
 78  hh_cmnty_cli.2          2700 non-null   float64
 79  nohh_cmnty_cli.2        2700 non-null   float64
 80  wearing_mask.2          2700 non-null   float64
 81  travel_outside_state.2  2700 non-null   float64
 82  work_outside_home.2     2700 non-null   float64
 83  shop.2                  2700 non-null   float64
 84  restaurant.2            2700 non-null   float64
 85  spent_time.2            2700 non-null   float64
 86  large_event.2           2700 non-null   float64
 87  public_transit.2        2700 non-null   float64
 88  anxious.2               2700 non-null   float64
 89  depressed.2             2700 non-null   float64
 90  felt_isolated.2         2700 non-null   float64
 91  worried_become_ill.2    2700 non-null   float64
 92  worried_finances.2      2700 non-null   float64
 93  tested_positive.2       2700 non-null   float64
dtypes: float64(94)
memory usage: 1.9 MB
None
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># WI列是states one-hot编码最后一列，取值为0或1，后面特征分析时需要把states特征删掉</span></span><br><span class="line">WI_index = cols.index(<span class="string">&#x27;WI&#x27;</span>)</span><br><span class="line"><span class="comment"># wi列索引 39</span></span><br><span class="line">WI_index </span><br></pre></td></tr></table></figure><pre><code>39
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从上面可以看出wi 列后面是cli, 所以列索引从40开始， 并查看这些数据分布</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">loc函数：通过索引 &quot;Index&quot; 中的具体值来取行数据（如取&quot;Index&quot;为&quot;A&quot;的行）</span></span><br><span class="line"><span class="string">    dataFrame.loc[:, :]</span></span><br><span class="line"><span class="string">iloc函数：通过行号、列号来取行数据（如取第二行的数据） </span></span><br><span class="line"><span class="string">    dataFrame.iloc[:, :] -&gt; dataFrame.iloc[x.begin: x.end, y.begin: y.end]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">data_tr.iloc[:, <span class="number">40</span>:].describe() </span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><p></p><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>cli</th><th>ili</th><th>hh_cmnty_cli</th><th>nohh_cmnty_cli</th><th>wearing_mask</th><th>travel_outside_state</th><th>work_outside_home</th><th>shop</th><th>restaurant</th><th>spent_time</th><th>...</th><th>restaurant.2</th><th>spent_time.2</th><th>large_event.2</th><th>public_transit.2</th><th>anxious.2</th><th>depressed.2</th><th>felt_isolated.2</th><th>worried_become_ill.2</th><th>worried_finances.2</th><th>tested_positive.2</th></tr></thead><tbody><tr><th>count</th><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>...</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td><td>2700.000000</td></tr><tr><th>mean</th><td>0.991587</td><td>1.016136</td><td>29.442496</td><td>24.323054</td><td>89.682322</td><td>8.894498</td><td>31.703307</td><td>55.277153</td><td>16.694342</td><td>36.283177</td><td>...</td><td>16.578290</td><td>36.074941</td><td>10.257474</td><td>2.385735</td><td>18.067635</td><td>13.058828</td><td>19.243283</td><td>64.834307</td><td>44.568440</td><td>16.431280</td></tr><tr><th>std</th><td>0.420296</td><td>0.423629</td><td>9.093738</td><td>8.446750</td><td>5.380027</td><td>3.404027</td><td>4.928902</td><td>4.525917</td><td>5.668479</td><td>6.675206</td><td>...</td><td>5.651583</td><td>6.655166</td><td>4.686263</td><td>1.053147</td><td>2.250081</td><td>1.628589</td><td>2.708339</td><td>6.220087</td><td>5.232030</td><td>7.619354</td></tr><tr><th>min</th><td>0.126321</td><td>0.132470</td><td>9.961640</td><td>6.857181</td><td>70.950912</td><td>1.252983</td><td>18.311941</td><td>43.220187</td><td>3.637414</td><td>21.485815</td><td>...</td><td>3.637414</td><td>21.485815</td><td>2.118674</td><td>0.728770</td><td>12.980786</td><td>8.370536</td><td>13.400399</td><td>48.225603</td><td>33.113882</td><td>2.338708</td></tr><tr><th>25%</th><td>0.673929</td><td>0.697515</td><td>23.203165</td><td>18.539153</td><td>86.309537</td><td>6.177754</td><td>28.247865</td><td>51.547206</td><td>13.311050</td><td>30.740931</td><td>...</td><td>13.200532</td><td>30.606711</td><td>6.532543</td><td>1.714080</td><td>16.420485</td><td>11.914167</td><td>17.322912</td><td>59.782876</td><td>40.549987</td><td>10.327314</td></tr><tr><th>50%</th><td>0.912747</td><td>0.940295</td><td>28.955738</td><td>23.819761</td><td>90.819435</td><td>8.288288</td><td>32.143140</td><td>55.257262</td><td>16.371699</td><td>36.267966</td><td>...</td><td>16.227010</td><td>36.041389</td><td>9.700368</td><td>2.199521</td><td>17.684197</td><td>12.948749</td><td>18.760267</td><td>65.932259</td><td>43.997637</td><td>15.646480</td></tr><tr><th>75%</th><td>1.266849</td><td>1.302040</td><td>36.109114</td><td>30.238061</td><td>93.937119</td><td>11.582209</td><td>35.387315</td><td>58.866130</td><td>21.396971</td><td>41.659971</td><td>...</td><td>21.207162</td><td>41.508520</td><td>13.602566</td><td>2.730469</td><td>19.503419</td><td>14.214320</td><td>20.713638</td><td>69.719651</td><td>48.118283</td><td>22.535165</td></tr><tr><th>max</th><td>2.597732</td><td>2.625885</td><td>56.832289</td><td>51.550450</td><td>98.087160</td><td>18.552325</td><td>42.359074</td><td>65.673889</td><td>28.488220</td><td>50.606465</td><td>...</td><td>28.488220</td><td>50.606465</td><td>24.496711</td><td>8.162275</td><td>28.574091</td><td>18.715944</td><td>28.366270</td><td>77.701014</td><td>58.433600</td><td>40.959495</td></tr></tbody></table><p>8 rows × 54 columns</p></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看测试集数据分布，并和训练集数据分布对比，两者特征之间数据分布差异不是很大</span></span><br><span class="line">data_tt.iloc[:, <span class="number">40</span>:].describe()</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><p></p><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>cli</th><th>ili</th><th>hh_cmnty_cli</th><th>nohh_cmnty_cli</th><th>wearing_mask</th><th>travel_outside_state</th><th>work_outside_home</th><th>shop</th><th>restaurant</th><th>spent_time</th><th>...</th><th>shop.2</th><th>restaurant.2</th><th>spent_time.2</th><th>large_event.2</th><th>public_transit.2</th><th>anxious.2</th><th>depressed.2</th><th>felt_isolated.2</th><th>worried_become_ill.2</th><th>worried_finances.2</th></tr></thead><tbody><tr><th>count</th><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>...</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td><td>893.000000</td></tr><tr><th>mean</th><td>0.972457</td><td>0.991809</td><td>29.075682</td><td>24.018729</td><td>89.637506</td><td>9.001325</td><td>31.620607</td><td>55.422982</td><td>16.554387</td><td>36.371653</td><td>...</td><td>55.268628</td><td>16.444916</td><td>36.165898</td><td>10.248975</td><td>2.369115</td><td>17.988147</td><td>12.993830</td><td>19.238723</td><td>64.619920</td><td>44.411505</td></tr><tr><th>std</th><td>0.411997</td><td>0.415468</td><td>9.596290</td><td>8.988245</td><td>4.733549</td><td>3.655616</td><td>4.754570</td><td>4.366780</td><td>5.688802</td><td>6.203232</td><td>...</td><td>4.350540</td><td>5.656828</td><td>6.192274</td><td>4.498845</td><td>1.114366</td><td>2.207022</td><td>1.713143</td><td>2.687435</td><td>5.685865</td><td>4.605268</td></tr><tr><th>min</th><td>0.139558</td><td>0.159477</td><td>9.171315</td><td>6.014740</td><td>76.895278</td><td>2.062500</td><td>18.299198</td><td>44.062442</td><td>3.800684</td><td>21.487077</td><td>...</td><td>44.671891</td><td>3.837441</td><td>21.338425</td><td>2.334655</td><td>0.873986</td><td>12.696977</td><td>8.462444</td><td>13.476209</td><td>50.212234</td><td>35.072577</td></tr><tr><th>25%</th><td>0.673327</td><td>0.689367</td><td>21.831730</td><td>17.385490</td><td>86.587475</td><td>7.055039</td><td>28.755178</td><td>51.726987</td><td>13.314242</td><td>31.427591</td><td>...</td><td>51.594301</td><td>13.391769</td><td>31.330469</td><td>6.802860</td><td>1.760374</td><td>16.406397</td><td>11.777101</td><td>17.197313</td><td>60.358203</td><td>40.910546</td></tr><tr><th>50%</th><td>0.925230</td><td>0.936610</td><td>28.183014</td><td>23.035749</td><td>90.123133</td><td>8.773243</td><td>31.826385</td><td>55.750887</td><td>17.100556</td><td>36.692799</td><td>...</td><td>55.490325</td><td>16.975410</td><td>36.213594</td><td>9.550393</td><td>2.146468</td><td>17.719760</td><td>12.805424</td><td>19.068658</td><td>65.148128</td><td>44.504010</td></tr><tr><th>75%</th><td>1.251219</td><td>1.267463</td><td>36.813772</td><td>31.141866</td><td>93.387952</td><td>10.452262</td><td>35.184926</td><td>59.185350</td><td>20.919961</td><td>41.265159</td><td>...</td><td>59.078475</td><td>20.584376</td><td>41.071035</td><td>13.372731</td><td>2.645314</td><td>19.423720</td><td>14.091551</td><td>21.205695</td><td>68.994309</td><td>47.172065</td></tr><tr><th>max</th><td>2.488967</td><td>2.522263</td><td>53.184067</td><td>48.142433</td><td>97.843221</td><td>26.598752</td><td>42.887263</td><td>63.979007</td><td>27.438286</td><td>53.513289</td><td>...</td><td>63.771097</td><td>27.362321</td><td>52.045373</td><td>23.305630</td><td>9.118302</td><td>27.003564</td><td>18.964157</td><td>26.007557</td><td>76.871053</td><td>56.442135</td></tr></tbody></table><p>8 rows × 53 columns</p></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># For plotting</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> figure</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="comment"># 肉眼分析cli特征与目标之间相关性</span></span><br><span class="line">plt.scatter(data_tr.loc[:, <span class="string">&#x27;cli&#x27;</span>], data_tr.loc[:, <span class="string">&#x27;tested_positive.2&#x27;</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x16c331670&gt;
</code></pre><p><img src="https://inews.gtimg.com/newsapp_ls/0/14146701183/0" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.scatter(data_tr.loc[:, <span class="string">&#x27;ili&#x27;</span>], data_tr.loc[:, <span class="string">&#x27;tested_positive.2&#x27;</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x1380acf40&gt;
</code></pre><p><img src="https://inews.gtimg.com/newsapp_ls/0/14146701910/0" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cli 和ili两者差不多，所以这两个特征用一个就行</span></span><br><span class="line">plt.scatter(data_tr.loc[:, <span class="string">&#x27;cli&#x27;</span>], data_tr.loc[:, <span class="string">&#x27;ili&#x27;</span>])  </span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x13811ca30&gt;
</code></pre><p><img src="https://inews.gtimg.com/newsapp_ls/0/14146702711/0" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#day1 目标值与day3目标值相关性，线性相关的</span></span><br><span class="line">plt.scatter(data_tr.loc[:,  <span class="string">&#x27;tested_positive&#x27;</span>], data_tr.loc[:, <span class="string">&#x27;tested_positive.2&#x27;</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x13815b730&gt;
</code></pre><p><img src="https://inews.gtimg.com/newsapp_ls/0/14146703460/0" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># day2 目标值与day3目标值相关性，线性相关的</span></span><br><span class="line">plt.scatter(data_tr.loc[:,  <span class="string">&#x27;tested_positive.1&#x27;</span>], data_tr.loc[:, <span class="string">&#x27;tested_positive.2&#x27;</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x1381ee190&gt;
</code></pre><p><img src="https://inews.gtimg.com/newsapp_ls/0/14146704407/0" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 上面手动分析太累，还是利用corr方法自动分析</span></span><br><span class="line">data_tr.iloc[:, <span class="number">40</span>:].corr() </span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><p></p><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>cli</th><th>ili</th><th>hh_cmnty_cli</th><th>nohh_cmnty_cli</th><th>wearing_mask</th><th>travel_outside_state</th><th>work_outside_home</th><th>shop</th><th>restaurant</th><th>spent_time</th><th>...</th><th>restaurant.2</th><th>spent_time.2</th><th>large_event.2</th><th>public_transit.2</th><th>anxious.2</th><th>depressed.2</th><th>felt_isolated.2</th><th>worried_become_ill.2</th><th>worried_finances.2</th><th>tested_positive.2</th></tr></thead><tbody><tr><th>cli</th><td>1.000000</td><td>0.995735</td><td>0.893416</td><td>0.882322</td><td>-0.107406</td><td>-0.095964</td><td>0.087305</td><td>-0.364165</td><td>-0.143318</td><td>-0.209020</td><td>...</td><td>-0.151291</td><td>-0.222834</td><td>-0.060308</td><td>-0.374071</td><td>0.237135</td><td>0.081456</td><td>0.098345</td><td>0.228750</td><td>0.550564</td><td>0.838504</td></tr><tr><th>ili</th><td>0.995735</td><td>1.000000</td><td>0.889729</td><td>0.878280</td><td>-0.109015</td><td>-0.106934</td><td>0.086355</td><td>-0.357443</td><td>-0.142082</td><td>-0.207210</td><td>...</td><td>-0.150141</td><td>-0.220942</td><td>-0.061298</td><td>-0.363873</td><td>0.245228</td><td>0.086229</td><td>0.104250</td><td>0.222909</td><td>0.544776</td><td>0.830527</td></tr><tr><th>hh_cmnty_cli</th><td>0.893416</td><td>0.889729</td><td>1.000000</td><td>0.997225</td><td>-0.035441</td><td>-0.069595</td><td>0.079219</td><td>-0.472746</td><td>-0.247043</td><td>-0.293775</td><td>...</td><td>-0.253615</td><td>-0.300062</td><td>-0.136937</td><td>-0.433276</td><td>0.307581</td><td>0.181497</td><td>0.203577</td><td>0.350255</td><td>0.561942</td><td>0.879724</td></tr><tr><th>nohh_cmnty_cli</th><td>0.882322</td><td>0.878280</td><td>0.997225</td><td>1.000000</td><td>-0.046063</td><td>-0.061914</td><td>0.097756</td><td>-0.465374</td><td>-0.238106</td><td>-0.280916</td><td>...</td><td>-0.245265</td><td>-0.287482</td><td>-0.129474</td><td>-0.424996</td><td>0.317836</td><td>0.188467</td><td>0.203599</td><td>0.345448</td><td>0.534711</td><td>0.869938</td></tr><tr><th>wearing_mask</th><td>-0.107406</td><td>-0.109015</td><td>-0.035441</td><td>-0.046063</td><td>1.000000</td><td>-0.220808</td><td>-0.735649</td><td>-0.691597</td><td>-0.788714</td><td>-0.807623</td><td>...</td><td>-0.785281</td><td>-0.802659</td><td>-0.889021</td><td>0.133487</td><td>0.204031</td><td>-0.067720</td><td>0.427533</td><td>0.840528</td><td>0.340101</td><td>-0.069531</td></tr><tr><th>travel_outside_state</th><td>-0.095964</td><td>-0.106934</td><td>-0.069595</td><td>-0.061914</td><td>-0.220808</td><td>1.000000</td><td>0.264107</td><td>0.256911</td><td>0.288473</td><td>0.349829</td><td>...</td><td>0.288098</td><td>0.336937</td><td>0.319736</td><td>-0.203611</td><td>0.001592</td><td>0.064425</td><td>-0.370776</td><td>-0.131961</td><td>-0.093096</td><td>-0.097303</td></tr><tr><th>work_outside_home</th><td>0.087305</td><td>0.086355</td><td>0.079219</td><td>0.097756</td><td>-0.735649</td><td>0.264107</td><td>1.000000</td><td>0.631958</td><td>0.743673</td><td>0.698047</td><td>...</td><td>0.730349</td><td>0.705533</td><td>0.758575</td><td>-0.110176</td><td>0.018259</td><td>0.075562</td><td>-0.430307</td><td>-0.652231</td><td>-0.317717</td><td>0.034865</td></tr><tr><th>shop</th><td>-0.364165</td><td>-0.357443</td><td>-0.472746</td><td>-0.465374</td><td>-0.691597</td><td>0.256911</td><td>0.631958</td><td>1.000000</td><td>0.820916</td><td>0.819035</td><td>...</td><td>0.811055</td><td>0.838358</td><td>0.787237</td><td>0.130046</td><td>-0.228007</td><td>-0.029168</td><td>-0.496368</td><td>-0.866789</td><td>-0.475304</td><td>-0.410430</td></tr><tr><th>restaurant</th><td>-0.143318</td><td>-0.142082</td><td>-0.247043</td><td>-0.238106</td><td>-0.788714</td><td>0.288473</td><td>0.743673</td><td>0.820916</td><td>1.000000</td><td>0.878576</td><td>...</td><td>0.993358</td><td>0.876107</td><td>0.909089</td><td>-0.046081</td><td>-0.278715</td><td>-0.074727</td><td>-0.648631</td><td>-0.832131</td><td>-0.430842</td><td>-0.157945</td></tr><tr><th>spent_time</th><td>-0.209020</td><td>-0.207210</td><td>-0.293775</td><td>-0.280916</td><td>-0.807623</td><td>0.349829</td><td>0.698047</td><td>0.819035</td><td>0.878576</td><td>1.000000</td><td>...</td><td>0.875365</td><td>0.986713</td><td>0.912682</td><td>-0.040623</td><td>-0.169965</td><td>0.105281</td><td>-0.517139</td><td>-0.867460</td><td>-0.522985</td><td>-0.252125</td></tr><tr><th>large_event</th><td>-0.042033</td><td>-0.043535</td><td>-0.124151</td><td>-0.116761</td><td>-0.894970</td><td>0.324270</td><td>0.767305</td><td>0.781862</td><td>0.912449</td><td>0.918504</td><td>...</td><td>0.910579</td><td>0.913814</td><td>0.993111</td><td>-0.139139</td><td>-0.215598</td><td>0.055579</td><td>-0.565014</td><td>-0.874083</td><td>-0.372589</td><td>-0.052473</td></tr><tr><th>public_transit</th><td>-0.367103</td><td>-0.356652</td><td>-0.432142</td><td>-0.423773</td><td>0.131350</td><td>-0.198308</td><td>-0.110077</td><td>0.132385</td><td>-0.043954</td><td>-0.037282</td><td>...</td><td>-0.048799</td><td>-0.035965</td><td>-0.137080</td><td>0.982095</td><td>-0.055799</td><td>-0.167599</td><td>0.001697</td><td>-0.046611</td><td>-0.138801</td><td>-0.448360</td></tr><tr><th>anxious</th><td>0.273874</td><td>0.281974</td><td>0.336748</td><td>0.344074</td><td>0.232620</td><td>-0.023175</td><td>0.013537</td><td>-0.265503</td><td>-0.312912</td><td>-0.209830</td><td>...</td><td>-0.327660</td><td>-0.218920</td><td>-0.283515</td><td>-0.054270</td><td>0.951196</td><td>0.539596</td><td>0.516252</td><td>0.280087</td><td>0.217988</td><td>0.173295</td></tr><tr><th>depressed</th><td>0.098033</td><td>0.102715</td><td>0.184739</td><td>0.190062</td><td>-0.070022</td><td>0.058548</td><td>0.075801</td><td>-0.041607</td><td>-0.074059</td><td>0.104628</td><td>...</td><td>-0.065903</td><td>0.113934</td><td>0.063086</td><td>-0.165972</td><td>0.599423</td><td>0.953157</td><td>0.592656</td><td>-0.055694</td><td>0.021274</td><td>0.037689</td></tr><tr><th>felt_isolated</th><td>0.100928</td><td>0.107079</td><td>0.198176</td><td>0.197661</td><td>0.422058</td><td>-0.376858</td><td>-0.431247</td><td>-0.491608</td><td>-0.642316</td><td>-0.511772</td><td>...</td><td>-0.633869</td><td>-0.497951</td><td>-0.544678</td><td>0.009742</td><td>0.526345</td><td>0.604416</td><td>0.978303</td><td>0.395606</td><td>0.128047</td><td>0.082182</td></tr><tr><th>worried_become_ill</th><td>0.218502</td><td>0.212931</td><td>0.344457</td><td>0.340192</td><td>0.843990</td><td>-0.136811</td><td>-0.656085</td><td>-0.864583</td><td>-0.835101</td><td>-0.870365</td><td>...</td><td>-0.831439</td><td>-0.869933</td><td>-0.872394</td><td>-0.043575</td><td>0.251045</td><td>-0.038421</td><td>0.419940</td><td>0.992976</td><td>0.490127</td><td>0.262211</td></tr><tr><th>worried_finances</th><td>0.537608</td><td>0.532217</td><td>0.552431</td><td>0.524022</td><td>0.354130</td><td>-0.096444</td><td>-0.339975</td><td>-0.489539</td><td>-0.447892</td><td>-0.536561</td><td>...</td><td>-0.451124</td><td>-0.536959</td><td>-0.397443</td><td>-0.141140</td><td>0.152500</td><td>0.027382</td><td>0.144230</td><td>0.506907</td><td>0.988123</td><td>0.475462</td></tr><tr><th>tested_positive</th><td>0.839122</td><td>0.829756</td><td>0.880187</td><td>0.869674</td><td>-0.049350</td><td>-0.113726</td><td>0.025780</td><td>-0.427815</td><td>-0.173726</td><td>-0.275476</td><td>...</td><td>-0.174815</td><td>-0.278257</td><td>-0.083275</td><td>-0.451809</td><td>0.132802</td><td>0.021773</td><td>0.090015</td><td>0.285052</td><td>0.495753</td><td>0.981165</td></tr><tr><th>cli.1</th><td>0.980379</td><td>0.977225</td><td>0.887944</td><td>0.877606</td><td>-0.121569</td><td>-0.091186</td><td>0.096755</td><td>-0.348133</td><td>-0.129772</td><td>-0.189519</td><td>...</td><td>-0.138355</td><td>-0.204750</td><td>-0.044520</td><td>-0.369066</td><td>0.254911</td><td>0.088243</td><td>0.093092</td><td>0.212721</td><td>0.540981</td><td>0.838224</td></tr><tr><th>ili.1</th><td>0.976171</td><td>0.980473</td><td>0.884020</td><td>0.873424</td><td>-0.123680</td><td>-0.102645</td><td>0.096343</td><td>-0.340973</td><td>-0.128114</td><td>-0.187173</td><td>...</td><td>-0.136904</td><td>-0.202412</td><td>-0.045430</td><td>-0.358447</td><td>0.263278</td><td>0.092825</td><td>0.099412</td><td>0.206378</td><td>0.534751</td><td>0.829200</td></tr><tr><th>hh_cmnty_cli.1</th><td>0.896211</td><td>0.892667</td><td>0.998356</td><td>0.996165</td><td>-0.046423</td><td>-0.063619</td><td>0.089934</td><td>-0.462807</td><td>-0.235459</td><td>-0.280262</td><td>...</td><td>-0.242962</td><td>-0.288664</td><td>-0.125902</td><td>-0.432234</td><td>0.319697</td><td>0.180703</td><td>0.195294</td><td>0.340223</td><td>0.556547</td><td>0.879438</td></tr><tr><th>nohh_cmnty_cli.1</th><td>0.885178</td><td>0.881292</td><td>0.995176</td><td>0.998259</td><td>-0.056529</td><td>-0.055823</td><td>0.107979</td><td>-0.455990</td><td>-0.226870</td><td>-0.268086</td><td>...</td><td>-0.234893</td><td>-0.276769</td><td>-0.119138</td><td>-0.423434</td><td>0.328817</td><td>0.186480</td><td>0.195257</td><td>0.336189</td><td>0.528994</td><td>0.869278</td></tr><tr><th>wearing_mask.1</th><td>-0.101056</td><td>-0.102606</td><td>-0.030237</td><td>-0.040738</td><td>0.998287</td><td>-0.220397</td><td>-0.732848</td><td>-0.694338</td><td>-0.789257</td><td>-0.808963</td><td>...</td><td>-0.787873</td><td>-0.806218</td><td>-0.892712</td><td>0.130892</td><td>0.208011</td><td>-0.071689</td><td>0.425830</td><td>0.843469</td><td>0.342057</td><td>-0.065600</td></tr><tr><th>travel_outside_state.1</th><td>-0.097092</td><td>-0.107662</td><td>-0.069270</td><td>-0.062039</td><td>-0.220442</td><td>0.995838</td><td>0.259748</td><td>0.261335</td><td>0.286921</td><td>0.352038</td><td>...</td><td>0.287332</td><td>0.342678</td><td>0.321376</td><td>-0.202010</td><td>-0.003803</td><td>0.065990</td><td>-0.372008</td><td>-0.133520</td><td>-0.090896</td><td>-0.100407</td></tr><tr><th>work_outside_home.1</th><td>0.087080</td><td>0.085966</td><td>0.074972</td><td>0.093529</td><td>-0.737554</td><td>0.268864</td><td>0.991471</td><td>0.616394</td><td>0.746680</td><td>0.697270</td><td>...</td><td>0.737749</td><td>0.698691</td><td>0.761755</td><td>-0.110337</td><td>0.025430</td><td>0.077455</td><td>-0.429387</td><td>-0.652367</td><td>-0.325294</td><td>0.037930</td></tr><tr><th>shop.1</th><td>-0.367850</td><td>-0.361304</td><td>-0.474799</td><td>-0.467316</td><td>-0.688627</td><td>0.252461</td><td>0.638500</td><td>0.991248</td><td>0.820264</td><td>0.808526</td><td>...</td><td>0.815317</td><td>0.829363</td><td>0.785631</td><td>0.131734</td><td>-0.232298</td><td>-0.029772</td><td>-0.492524</td><td>-0.864694</td><td>-0.478978</td><td>-0.412705</td></tr><tr><th>restaurant.1</th><td>-0.147491</td><td>-0.146353</td><td>-0.250349</td><td>-0.241687</td><td>-0.787245</td><td>0.288160</td><td>0.737725</td><td>0.816414</td><td>0.997496</td><td>0.877051</td><td>...</td><td>0.997484</td><td>0.876508</td><td>0.911182</td><td>-0.046082</td><td>-0.285147</td><td>-0.070812</td><td>-0.645411</td><td>-0.832047</td><td>-0.433497</td><td>-0.159121</td></tr><tr><th>spent_time.1</th><td>-0.216168</td><td>-0.214354</td><td>-0.297071</td><td>-0.284398</td><td>-0.805468</td><td>0.343854</td><td>0.700146</td><td>0.828992</td><td>0.877660</td><td>0.995393</td><td>...</td><td>0.876180</td><td>0.995383</td><td>0.916829</td><td>-0.039405</td><td>-0.175019</td><td>0.111992</td><td>-0.513196</td><td>-0.869427</td><td>-0.523476</td><td>-0.255714</td></tr><tr><th>large_event.1</th><td>-0.051724</td><td>-0.052961</td><td>-0.130729</td><td>-0.123252</td><td>-0.892267</td><td>0.322149</td><td>0.762592</td><td>0.784996</td><td>0.911143</td><td>0.916514</td><td>...</td><td>0.912015</td><td>0.917360</td><td>0.997449</td><td>-0.137279</td><td>-0.226287</td><td>0.061477</td><td>-0.559791</td><td>-0.875258</td><td>-0.376785</td><td>-0.058079</td></tr><tr><th>public_transit.1</th><td>-0.371063</td><td>-0.360574</td><td>-0.432765</td><td>-0.424445</td><td>0.132301</td><td>-0.201241</td><td>-0.109727</td><td>0.131371</td><td>-0.044942</td><td>-0.039224</td><td>...</td><td>-0.047397</td><td>-0.036646</td><td>-0.136200</td><td>0.991364</td><td>-0.053367</td><td>-0.165462</td><td>0.005809</td><td>-0.047158</td><td>-0.140425</td><td>-0.449079</td></tr><tr><th>anxious.1</th><td>0.256712</td><td>0.264872</td><td>0.323053</td><td>0.331791</td><td>0.217574</td><td>-0.011044</td><td>0.018079</td><td>-0.246039</td><td>-0.295416</td><td>-0.189704</td><td>...</td><td>-0.309644</td><td>-0.199497</td><td>-0.260678</td><td>-0.053189</td><td>0.980965</td><td>0.567651</td><td>0.519936</td><td>0.264619</td><td>0.201912</td><td>0.164537</td></tr><tr><th>depressed.1</th><td>0.088676</td><td>0.093371</td><td>0.182383</td><td>0.188544</td><td>-0.069369</td><td>0.061782</td><td>0.075357</td><td>-0.034364</td><td>-0.073814</td><td>0.105809</td><td>...</td><td>-0.066076</td><td>0.117099</td><td>0.065712</td><td>-0.164973</td><td>0.599952</td><td>0.978623</td><td>0.601982</td><td>-0.054501</td><td>0.024123</td><td>0.033149</td></tr><tr><th>felt_isolated.1</th><td>0.099487</td><td>0.105446</td><td>0.201034</td><td>0.200843</td><td>0.424822</td><td>-0.374146</td><td>-0.430562</td><td>-0.493842</td><td>-0.645507</td><td>-0.514850</td><td>...</td><td>-0.638136</td><td>-0.503093</td><td>-0.549472</td><td>0.009842</td><td>0.527040</td><td>0.608896</td><td>0.990446</td><td>0.401543</td><td>0.130005</td><td>0.081521</td></tr><tr><th>worried_become_ill.1</th><td>0.223326</td><td>0.217739</td><td>0.347562</td><td>0.343024</td><td>0.842499</td><td>-0.134507</td><td>-0.654251</td><td>-0.865601</td><td>-0.833903</td><td>-0.869399</td><td>...</td><td>-0.832038</td><td>-0.870442</td><td>-0.874175</td><td>-0.045239</td><td>0.250985</td><td>-0.044886</td><td>0.414444</td><td>0.996878</td><td>0.492998</td><td>0.264816</td></tr><tr><th>worried_finances.1</th><td>0.543373</td><td>0.537874</td><td>0.557364</td><td>0.529514</td><td>0.347359</td><td>-0.094679</td><td>-0.328919</td><td>-0.482534</td><td>-0.439702</td><td>-0.529935</td><td>...</td><td>-0.444050</td><td>-0.531072</td><td>-0.389929</td><td>-0.141796</td><td>0.168931</td><td>0.026522</td><td>0.138286</td><td>0.501713</td><td>0.994864</td><td>0.480958</td></tr><tr><th>tested_positive.1</th><td>0.839929</td><td>0.831129</td><td>0.880416</td><td>0.870315</td><td>-0.059477</td><td>-0.105467</td><td>0.031094</td><td>-0.419104</td><td>-0.165959</td><td>-0.264309</td><td>...</td><td>-0.167639</td><td>-0.268959</td><td>-0.073982</td><td>-0.451397</td><td>0.143395</td><td>0.025272</td><td>0.085417</td><td>0.276338</td><td>0.491043</td><td>0.991012</td></tr><tr><th>cli.2</th><td>0.957059</td><td>0.954996</td><td>0.881768</td><td>0.872292</td><td>-0.135146</td><td>-0.086332</td><td>0.104981</td><td>-0.331428</td><td>-0.116415</td><td>-0.170275</td><td>...</td><td>-0.124823</td><td>-0.185582</td><td>-0.027097</td><td>-0.363815</td><td>0.270811</td><td>0.096270</td><td>0.087526</td><td>0.197407</td><td>0.532770</td><td>0.835751</td></tr><tr><th>ili.2</th><td>0.952707</td><td>0.956979</td><td>0.877550</td><td>0.867896</td><td>-0.137841</td><td>-0.097991</td><td>0.104965</td><td>-0.323789</td><td>-0.114323</td><td>-0.167358</td><td>...</td><td>-0.123005</td><td>-0.182693</td><td>-0.027895</td><td>-0.353209</td><td>0.279485</td><td>0.100997</td><td>0.094463</td><td>0.190436</td><td>0.526026</td><td>0.826075</td></tr><tr><th>hh_cmnty_cli.2</th><td>0.898067</td><td>0.894564</td><td>0.995396</td><td>0.993750</td><td>-0.058149</td><td>-0.057164</td><td>0.099741</td><td>-0.452086</td><td>-0.223203</td><td>-0.265245</td><td>...</td><td>-0.231610</td><td>-0.275863</td><td>-0.113619</td><td>-0.431142</td><td>0.330882</td><td>0.180963</td><td>0.186653</td><td>0.329330</td><td>0.550290</td><td>0.878218</td></tr><tr><th>nohh_cmnty_cli.2</th><td>0.887103</td><td>0.883263</td><td>0.991738</td><td>0.995093</td><td>-0.067698</td><td>-0.049281</td><td>0.117226</td><td>-0.445815</td><td>-0.215113</td><td>-0.253751</td><td>...</td><td>-0.223909</td><td>-0.264597</td><td>-0.107674</td><td>-0.421805</td><td>0.339048</td><td>0.185514</td><td>0.186517</td><td>0.326080</td><td>0.522506</td><td>0.867535</td></tr><tr><th>wearing_mask.2</th><td>-0.094664</td><td>-0.096315</td><td>-0.025367</td><td>-0.035759</td><td>0.995953</td><td>-0.219423</td><td>-0.729730</td><td>-0.696457</td><td>-0.788931</td><td>-0.809003</td><td>...</td><td>-0.789539</td><td>-0.808958</td><td>-0.895733</td><td>0.128696</td><td>0.212752</td><td>-0.075599</td><td>0.423325</td><td>0.845721</td><td>0.343891</td><td>-0.062037</td></tr><tr><th>travel_outside_state.2</th><td>-0.097903</td><td>-0.107903</td><td>-0.069043</td><td>-0.062137</td><td>-0.219916</td><td>0.989310</td><td>0.258430</td><td>0.266438</td><td>0.285380</td><td>0.352962</td><td>...</td><td>0.286899</td><td>0.347804</td><td>0.322521</td><td>-0.199731</td><td>-0.007996</td><td>0.067252</td><td>-0.372366</td><td>-0.135255</td><td>-0.089308</td><td>-0.103868</td></tr><tr><th>work_outside_home.2</th><td>0.085913</td><td>0.084708</td><td>0.069933</td><td>0.088394</td><td>-0.739112</td><td>0.275348</td><td>0.975017</td><td>0.599363</td><td>0.748185</td><td>0.700309</td><td>...</td><td>0.743692</td><td>0.695202</td><td>0.765953</td><td>-0.111477</td><td>0.028803</td><td>0.080485</td><td>-0.428880</td><td>-0.652395</td><td>-0.333070</td><td>0.039304</td></tr><tr><th>shop.2</th><td>-0.370197</td><td>-0.363795</td><td>-0.476538</td><td>-0.469026</td><td>-0.685437</td><td>0.249670</td><td>0.640972</td><td>0.977890</td><td>0.818073</td><td>0.800586</td><td>...</td><td>0.818509</td><td>0.819755</td><td>0.783057</td><td>0.132409</td><td>-0.237570</td><td>-0.031062</td><td>-0.488979</td><td>-0.862711</td><td>-0.482649</td><td>-0.415130</td></tr><tr><th>restaurant.2</th><td>-0.151291</td><td>-0.150141</td><td>-0.253615</td><td>-0.245265</td><td>-0.785281</td><td>0.288098</td><td>0.730349</td><td>0.811055</td><td>0.993358</td><td>0.875365</td><td>...</td><td>1.000000</td><td>0.876542</td><td>0.912564</td><td>-0.046246</td><td>-0.292246</td><td>-0.067040</td><td>-0.641984</td><td>-0.831868</td><td>-0.435929</td><td>-0.160181</td></tr><tr><th>spent_time.2</th><td>-0.222834</td><td>-0.220942</td><td>-0.300062</td><td>-0.287482</td><td>-0.802659</td><td>0.336937</td><td>0.705533</td><td>0.838358</td><td>0.876107</td><td>0.986713</td><td>...</td><td>0.876542</td><td>1.000000</td><td>0.918931</td><td>-0.037616</td><td>-0.180294</td><td>0.118125</td><td>-0.507902</td><td>-0.870630</td><td>-0.524228</td><td>-0.258956</td></tr><tr><th>large_event.2</th><td>-0.060308</td><td>-0.061298</td><td>-0.136937</td><td>-0.129474</td><td>-0.889021</td><td>0.319736</td><td>0.758575</td><td>0.787237</td><td>0.909089</td><td>0.912682</td><td>...</td><td>0.912564</td><td>0.918931</td><td>1.000000</td><td>-0.135339</td><td>-0.238586</td><td>0.066021</td><td>-0.554675</td><td>-0.875487</td><td>-0.380926</td><td>-0.063709</td></tr><tr><th>public_transit.2</th><td>-0.374071</td><td>-0.363873</td><td>-0.433276</td><td>-0.424996</td><td>0.133487</td><td>-0.203611</td><td>-0.110176</td><td>0.130046</td><td>-0.046081</td><td>-0.040623</td><td>...</td><td>-0.046246</td><td>-0.037616</td><td>-0.135339</td><td>1.000000</td><td>-0.052253</td><td>-0.164079</td><td>0.009571</td><td>-0.047068</td><td>-0.142098</td><td>-0.450436</td></tr><tr><th>anxious.2</th><td>0.237135</td><td>0.245228</td><td>0.307581</td><td>0.317836</td><td>0.204031</td><td>0.001592</td><td>0.018259</td><td>-0.228007</td><td>-0.278715</td><td>-0.169965</td><td>...</td><td>-0.292246</td><td>-0.180294</td><td>-0.238586</td><td>-0.052253</td><td>1.000000</td><td>0.594797</td><td>0.525171</td><td>0.251509</td><td>0.184126</td><td>0.152903</td></tr><tr><th>depressed.2</th><td>0.081456</td><td>0.086229</td><td>0.181497</td><td>0.188467</td><td>-0.067720</td><td>0.064425</td><td>0.075562</td><td>-0.029168</td><td>-0.074727</td><td>0.105281</td><td>...</td><td>-0.067040</td><td>0.118125</td><td>0.066021</td><td>-0.164079</td><td>0.594797</td><td>1.000000</td><td>0.610310</td><td>-0.051246</td><td>0.026621</td><td>0.029578</td></tr><tr><th>felt_isolated.2</th><td>0.098345</td><td>0.104250</td><td>0.203577</td><td>0.203599</td><td>0.427533</td><td>-0.370776</td><td>-0.430307</td><td>-0.496368</td><td>-0.648631</td><td>-0.517139</td><td>...</td><td>-0.641984</td><td>-0.507902</td><td>-0.554675</td><td>0.009571</td><td>0.525171</td><td>0.610310</td><td>1.000000</td><td>0.407931</td><td>0.132465</td><td>0.081174</td></tr><tr><th>worried_become_ill.2</th><td>0.228750</td><td>0.222909</td><td>0.350255</td><td>0.345448</td><td>0.840528</td><td>-0.131961</td><td>-0.652231</td><td>-0.866789</td><td>-0.832131</td><td>-0.867460</td><td>...</td><td>-0.831868</td><td>-0.870630</td><td>-0.875487</td><td>-0.047068</td><td>0.251509</td><td>-0.051246</td><td>0.407931</td><td>1.000000</td><td>0.495890</td><td>0.267610</td></tr><tr><th>worried_finances.2</th><td>0.550564</td><td>0.544776</td><td>0.561942</td><td>0.534711</td><td>0.340101</td><td>-0.093096</td><td>-0.317717</td><td>-0.475304</td><td>-0.430842</td><td>-0.522985</td><td>...</td><td>-0.435929</td><td>-0.524228</td><td>-0.380926</td><td>-0.142098</td><td>0.184126</td><td>0.026621</td><td>0.132465</td><td>0.495890</td><td>1.000000</td><td>0.485843</td></tr><tr><th>tested_positive.2</th><td>0.838504</td><td>0.830527</td><td>0.879724</td><td>0.869938</td><td>-0.069531</td><td>-0.097303</td><td>0.034865</td><td>-0.410430</td><td>-0.157945</td><td>-0.252125</td><td>...</td><td>-0.160181</td><td>-0.258956</td><td>-0.063709</td><td>-0.450436</td><td>0.152903</td><td>0.029578</td><td>0.081174</td><td>0.267610</td><td>0.485843</td><td>1.000000</td></tr></tbody></table><p>54 rows × 54 columns</p></div><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 锁定上面相关性矩阵最后一列，也就是目标值列，每行是与其相关性大小</span></span><br><span class="line">data_corr = data_tr.iloc[:, <span class="number">40</span>:].corr()</span><br><span class="line">target_col = data_corr[<span class="string">&#x27;tested_positive.2&#x27;</span>]</span><br><span class="line">target_col</span><br></pre></td></tr></table></figure><pre><code>cli                       0.838504
ili                       0.830527
hh_cmnty_cli              0.879724
nohh_cmnty_cli            0.869938
wearing_mask             -0.069531
travel_outside_state     -0.097303
work_outside_home         0.034865
shop                     -0.410430
restaurant               -0.157945
spent_time               -0.252125
large_event              -0.052473
public_transit           -0.448360
anxious                   0.173295
depressed                 0.037689
felt_isolated             0.082182
worried_become_ill        0.262211
worried_finances          0.475462
tested_positive           0.981165
cli.1                     0.838224
ili.1                     0.829200
hh_cmnty_cli.1            0.879438
nohh_cmnty_cli.1          0.869278
wearing_mask.1           -0.065600
travel_outside_state.1   -0.100407
work_outside_home.1       0.037930
shop.1                   -0.412705
restaurant.1             -0.159121
spent_time.1             -0.255714
large_event.1            -0.058079
public_transit.1         -0.449079
anxious.1                 0.164537
depressed.1               0.033149
felt_isolated.1           0.081521
worried_become_ill.1      0.264816
worried_finances.1        0.480958
tested_positive.1         0.991012
cli.2                     0.835751
ili.2                     0.826075
hh_cmnty_cli.2            0.878218
nohh_cmnty_cli.2          0.867535
wearing_mask.2           -0.062037
travel_outside_state.2   -0.103868
work_outside_home.2       0.039304
shop.2                   -0.415130
restaurant.2             -0.160181
spent_time.2             -0.258956
large_event.2            -0.063709
public_transit.2         -0.450436
anxious.2                 0.152903
depressed.2               0.029578
felt_isolated.2           0.081174
worried_become_ill.2      0.267610
worried_finances.2        0.485843
tested_positive.2         1.000000
Name: tested_positive.2, dtype: float64
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在最后一列相关性数据中选择大于0.8的行，这个0.8是自己设的超参，大家可以根据实际情况调节</span></span><br><span class="line">feature = target_col[target_col &gt; <span class="number">0.8</span>] </span><br><span class="line">feature</span><br></pre></td></tr></table></figure><pre><code>cli                  0.838504
ili                  0.830527
hh_cmnty_cli         0.879724
nohh_cmnty_cli       0.869938
tested_positive      0.981165
cli.1                0.838224
ili.1                0.829200
hh_cmnty_cli.1       0.879438
nohh_cmnty_cli.1     0.869278
tested_positive.1    0.991012
cli.2                0.835751
ili.2                0.826075
hh_cmnty_cli.2       0.878218
nohh_cmnty_cli.2     0.867535
tested_positive.2    1.000000
Name: tested_positive.2, dtype: float64
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">feature_cols = feature.index.tolist()  <span class="comment">#将选择特征名称拿出来</span></span><br><span class="line">feature_cols.pop() <span class="comment">#去掉test_positive标签</span></span><br><span class="line">pp.pprint(feature_cols) <span class="comment">#得到每个需要特征名称列表</span></span><br></pre></td></tr></table></figure><pre><code>[&#39;cli&#39;,
 &#39;ili&#39;,
 &#39;hh_cmnty_cli&#39;,
 &#39;nohh_cmnty_cli&#39;,
 &#39;tested_positive&#39;,
 &#39;cli.1&#39;,
 &#39;ili.1&#39;,
 &#39;hh_cmnty_cli.1&#39;,
 &#39;nohh_cmnty_cli.1&#39;,
 &#39;tested_positive.1&#39;,
 &#39;cli.2&#39;,
 &#39;ili.2&#39;,
 &#39;hh_cmnty_cli.2&#39;,
 &#39;nohh_cmnty_cli.2&#39;]
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取该特征对应列索引编号，后续就可以用feats + feats_selected作为特征值</span></span><br><span class="line">feats_selected = [cols.index(col) <span class="keyword">for</span> col <span class="keyword">in</span> feature_cols] </span><br><span class="line">feats_selected</span><br></pre></td></tr></table></figure><pre><code>[40, 41, 42, 43, 57, 58, 59, 60, 61, 75, 76, 77, 78, 79]
</code></pre><h2 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># PyTorch</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># For data preprocess</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># For plotting</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> figure</span><br><span class="line"></span><br><span class="line">myseed = <span class="number">42069</span>  <span class="comment"># set a random seed for reproducibility</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">np.random.seed(myseed)</span><br><span class="line">torch.manual_seed(myseed)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    torch.cuda.manual_seed_all(myseed)</span><br></pre></td></tr></table></figure><h2 id="导入工具"><a href="#导入工具" class="headerlink" title="导入工具"></a>导入工具</h2><p>无需修改</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_device</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Get device (if GPU is available, use GPU) &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span>(<span class="params">loss_record, title=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Plot learning curve of your DNN (train &amp; dev loss) &#x27;&#x27;&#x27;</span></span><br><span class="line">    total_steps = <span class="built_in">len</span>(loss_record[<span class="string">&#x27;train&#x27;</span>])</span><br><span class="line">    x_1 = <span class="built_in">range</span>(total_steps)</span><br><span class="line">    x_2 = x_1[::<span class="built_in">len</span>(loss_record[<span class="string">&#x27;train&#x27;</span>]) // <span class="built_in">len</span>(loss_record[<span class="string">&#x27;dev&#x27;</span>])]</span><br><span class="line">    figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">    plt.plot(x_1, loss_record[<span class="string">&#x27;train&#x27;</span>], c=<span class="string">&#x27;tab:red&#x27;</span>, label=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    plt.plot(x_2, loss_record[<span class="string">&#x27;dev&#x27;</span>], c=<span class="string">&#x27;tab:cyan&#x27;</span>, label=<span class="string">&#x27;dev&#x27;</span>)</span><br><span class="line">    plt.ylim(<span class="number">0.0</span>, <span class="number">5.</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Training steps&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;MSE loss&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Learning curve of &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(title))</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_pred</span>(<span class="params">dv_set, model, device, lim=<span class="number">35.</span>, preds=<span class="literal">None</span>, targets=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Plot prediction of your DNN &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> preds <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> targets <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        preds, targets = [], []</span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> dv_set:</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                pred = model(x)</span><br><span class="line">                preds.append(pred.detach().cpu())</span><br><span class="line">                targets.append(y.detach().cpu())</span><br><span class="line">        preds = torch.cat(preds, dim=<span class="number">0</span>).numpy()</span><br><span class="line">        targets = torch.cat(targets, dim=<span class="number">0</span>).numpy()</span><br><span class="line"></span><br><span class="line">    figure(figsize=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">    plt.scatter(targets, preds, c=<span class="string">&#x27;r&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.plot([-<span class="number">0.2</span>, lim], [-<span class="number">0.2</span>, lim], c=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    plt.xlim(-<span class="number">0.2</span>, lim)</span><br><span class="line">    plt.ylim(-<span class="number">0.2</span>, lim)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;ground truth value&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;predicted value&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Ground Truth v.s. Prediction&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>我们有三种数据集：</p><ul><li>训练集</li><li>验证集</li><li>测试集</li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>COVID19Dataset完成以下操作：</p><ol><li>读取.csv文件</li><li>提取特征</li><li>划分covid.train.csv为训练集和验证集</li><li>规范特征</li></ol><p>提示： 完成以下操作有可以通过中等难度的分数线</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># For data preprocess</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">COVID19Dataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Dataset for loading and preprocessing the COVID19 dataset &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, path, mu, std, mode=<span class="string">&#x27;train&#x27;</span>, target_only=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="comment"># mu,std是自己加，baseline代码归一化有问题，重写归一化部分</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化模型类别(训练、测试、验证)，默认是train</span></span><br><span class="line">        self.mode = mode</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Read data into numpy arrays</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            data = <span class="built_in">list</span>(csv.reader(fp))</span><br><span class="line">            <span class="comment"># 去除id列</span></span><br><span class="line">            data = np.array(data[<span class="number">1</span>:])[:, <span class="number">1</span>:].astype(<span class="built_in">float</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> target_only:</span><br><span class="line">            feats = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">93</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> Using 40 states &amp; 2 tested_positive features (indices = 57 &amp; 75)</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># feats_selected是我们选择特征, 40代表是states特征</span></span><br><span class="line">            feats = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">40</span>)) + feats_selected      </span><br><span class="line">            </span><br><span class="line">            <span class="comment">#如果用只用两个特征，可以忽略前面数据分析过程,直接这样写</span></span><br><span class="line">            <span class="comment">#feats = list(range(40)) + [57, 75]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            <span class="comment"># Testing data</span></span><br><span class="line">            <span class="comment"># data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))</span></span><br><span class="line">            data = data[:, feats]</span><br><span class="line">            self.data = torch.FloatTensor(data)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Training data (train/dev sets)</span></span><br><span class="line">            <span class="comment"># data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))</span></span><br><span class="line">            target = data[:, -<span class="number">1</span>]</span><br><span class="line">            data = data[:, feats]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Splitting training data into train &amp; dev sets</span></span><br><span class="line"><span class="comment">#             if mode == &#x27;train&#x27;:</span></span><br><span class="line"><span class="comment">#                 indices = [i for i in range(len(data)) if i % 10 != 0]</span></span><br><span class="line"><span class="comment">#             elif mode == &#x27;dev&#x27;:</span></span><br><span class="line"><span class="comment">#                 indices = [i for i in range(len(data)) if i % 10 == 0]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># baseline代码中，划分训练集和测试集按照顺序选择数据，可能造成数据分布问题，改成随机选择</span></span><br><span class="line">            indices_tr, indices_dev = train_test_split([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>])], test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> self.mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                indices = indices_tr</span><br><span class="line">            <span class="keyword">elif</span> self.mode == <span class="string">&#x27;dev&#x27;</span>:</span><br><span class="line">                indices = indices_dev</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Convert data into PyTorch tensors</span></span><br><span class="line">            self.data = torch.FloatTensor(data[indices])</span><br><span class="line">            self.target = torch.FloatTensor(target[indices])</span><br><span class="line">            </span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Normalize features (you may remove this part to see what will happen)</span></span><br><span class="line"><span class="comment">#         self.data[:, 40:] = \</span></span><br><span class="line"><span class="comment">#             (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \</span></span><br><span class="line"><span class="comment">#             / self.data[:, 40:].std(dim=0, keepdim=True)</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># baseline这段代码数据归一化用的是当前数据归一化，事实上验证集上和测试集上归一化一般只能用过去数据即训练集上均值和方差进行归一化</span></span><br><span class="line"><span class="comment">#         self.dim = self.data.shape[1]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         print(&#x27;Finished reading the &#123;&#125; set of COVID19 Dataset (&#123;&#125; samples found, each dim = &#123;&#125;)&#x27;</span></span><br><span class="line"><span class="comment">#               .format(mode, len(self.data), self.dim))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果是训练集，均值和方差用自己数据</span></span><br><span class="line">        <span class="keyword">if</span> self.mode == <span class="string">&quot;train&quot;</span>: </span><br><span class="line">            self.mu = self.data[:, <span class="number">40</span>:].mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">            self.std = self.data[:, <span class="number">40</span>:].std(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            <span class="comment"># 测试集和验证集，传进来的均值和方差是来自训练集保存，如何保存均值和方差，看数据dataload部分</span></span><br><span class="line">            self.mu = mu</span><br><span class="line">            self.std = std</span><br><span class="line"></span><br><span class="line">        self.data[:,<span class="number">40</span>:] = (self.data[:, <span class="number">40</span>:] - self.mu) / self.std  <span class="comment">#归一化</span></span><br><span class="line">        self.dim = self.data.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Finished reading the &#123;&#125; set of COVID19 Dataset (&#123;&#125; samples found, each dim = &#123;&#125;)&#x27;</span></span><br><span class="line">              .<span class="built_in">format</span>(mode, <span class="built_in">len</span>(self.data), self.dim))</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="comment"># Returns one sample at a time</span></span><br><span class="line">        <span class="keyword">if</span> self.mode <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>]:</span><br><span class="line">            <span class="comment"># For training</span></span><br><span class="line">            <span class="keyword">return</span> self.data[index], self.target[index]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># For testing (no target)</span></span><br><span class="line">            <span class="keyword">return</span> self.data[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># Returns the size of the dataset</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prep_dataloader</span>(<span class="params">path, mode, batch_size, n_jobs=<span class="number">0</span>, target_only=<span class="literal">False</span>, mu=<span class="literal">None</span>, std=<span class="literal">None</span></span>):</span> <span class="comment">#训练集不需要传mu,std, 所以默认值设置为None</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Generates a dataset, then is put into a dataloader. &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = COVID19Dataset(path, mu, std, mode=mode, target_only=target_only)  <span class="comment"># Construct dataset</span></span><br><span class="line">    <span class="comment"># 如果是训练集，把训练集上均值和方差保存下来</span></span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>:  </span><br><span class="line">        mu = dataset.mu</span><br><span class="line">        std = dataset.std</span><br><span class="line">    dataloader = DataLoader(</span><br><span class="line">        dataset, batch_size,</span><br><span class="line">        shuffle=(mode == <span class="string">&#x27;train&#x27;</span>), drop_last=<span class="literal">False</span>,</span><br><span class="line">        num_workers=n_jobs, pin_memory=<span class="literal">True</span>)                            <span class="comment"># Construct dataloader</span></span><br><span class="line">    <span class="keyword">return</span> dataloader, mu, std</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; A simple fully-connected deep neural network &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Define your neural network here</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> How to modify this model to achieve better performance?</span></span><br><span class="line">        <span class="comment"># 70是我调得最好的， 而且加层很容易过拟和</span></span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Linear(input_dim, <span class="number">68</span>),   </span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">68</span>,<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># Mean squared error loss</span></span><br><span class="line">        self.criterion = nn.MSELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Given input of size (batch_size x input_dim), compute output of the network &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> self.net(x).squeeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_loss</span>(<span class="params">self, pred, target</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; Calculate loss &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> you may implement L2 regularization here</span></span><br><span class="line">        eps = <span class="number">1e-6</span></span><br><span class="line">        l2_reg = <span class="number">0</span></span><br><span class="line">        alpha = <span class="number">0.0001</span></span><br><span class="line">        <span class="comment"># 这段代码是l2正则，但是实际操作l2正则效果不好，大家也可以调，把下面这段代码取消注释就行</span></span><br><span class="line"><span class="comment">#         for name, w in self.net.named_parameters():</span></span><br><span class="line"><span class="comment">#             if &#x27;weight&#x27;  in name:</span></span><br><span class="line"><span class="comment">#                 l2_reg += alpha * torch.norm(w, p = 2).to(device)</span></span><br><span class="line">        <span class="keyword">return</span> torch.sqrt(self.criterion(pred, target) + eps) + l2_reg   </span><br><span class="line">        <span class="comment">#lr_reg=0, 后面那段代码用的是均方根误差，均方根误差和kaggle评测指标一致，而且训练模型也更平稳</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">tr_set, dv_set, model, config, device</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; DNN training &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    n_epochs = config[<span class="string">&#x27;n_epochs&#x27;</span>]  <span class="comment"># Maximum number of epochs</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Setup optimizer</span></span><br><span class="line">    optimizer = <span class="built_in">getattr</span>(torch.optim, config[<span class="string">&#x27;optimizer&#x27;</span>])(</span><br><span class="line">        model.parameters(), **config[<span class="string">&#x27;optim_hparas&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    min_mse = <span class="number">1000.</span></span><br><span class="line">    loss_record = &#123;<span class="string">&#x27;train&#x27;</span>: [], <span class="string">&#x27;dev&#x27;</span>: []&#125;      <span class="comment"># for recording training loss</span></span><br><span class="line">    early_stop_cnt = <span class="number">0</span></span><br><span class="line">    epoch = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> epoch &lt; n_epochs:</span><br><span class="line">        model.train()                           <span class="comment"># set model to training mode</span></span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> tr_set:                     <span class="comment"># iterate through the dataloader</span></span><br><span class="line">            optimizer.zero_grad()               <span class="comment"># set gradient to zero</span></span><br><span class="line">            x, y = x.to(device), y.to(device)   <span class="comment"># move data to device (cpu/cuda)</span></span><br><span class="line">            pred = model(x)                     <span class="comment"># forward pass (compute output)</span></span><br><span class="line">            mse_loss = model.cal_loss(pred, y)  <span class="comment"># compute loss</span></span><br><span class="line">            mse_loss.backward()                 <span class="comment"># compute gradient (backpropagation)</span></span><br><span class="line">            optimizer.step()                    <span class="comment"># update model with optimizer</span></span><br><span class="line">            loss_record[<span class="string">&#x27;train&#x27;</span>].append(mse_loss.detach().cpu().item())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># After each epoch, test your model on the validation (development) set.</span></span><br><span class="line">        dev_mse = dev(dv_set, model, device)</span><br><span class="line">        <span class="keyword">if</span> dev_mse &lt; min_mse:</span><br><span class="line">            <span class="comment"># Save model if your model improved</span></span><br><span class="line">            min_mse = dev_mse</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Saving model (epoch = &#123;:4d&#125;, loss = &#123;:.4f&#125;)&#x27;</span></span><br><span class="line">                .<span class="built_in">format</span>(epoch + <span class="number">1</span>, min_mse))</span><br><span class="line">            torch.save(model.state_dict(), config[<span class="string">&#x27;save_path&#x27;</span>])  <span class="comment"># Save model to specified path</span></span><br><span class="line">            early_stop_cnt = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            early_stop_cnt += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        epoch += <span class="number">1</span></span><br><span class="line">        loss_record[<span class="string">&#x27;dev&#x27;</span>].append(dev_mse)</span><br><span class="line">        <span class="keyword">if</span> early_stop_cnt &gt; config[<span class="string">&#x27;early_stop&#x27;</span>]:</span><br><span class="line">            <span class="comment"># Stop training if your model stops improving for &quot;config[&#x27;early_stop&#x27;]&quot; epochs.</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Finished training after &#123;&#125; epochs&#x27;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line">    <span class="keyword">return</span> min_mse, loss_record</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dev</span>(<span class="params">dv_set, model, device</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()                                <span class="comment"># set model to evalutation mode</span></span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> dv_set:                         <span class="comment"># iterate through the dataloader</span></span><br><span class="line">        x, y = x.to(device), y.to(device)       <span class="comment"># move data to device (cpu/cuda)</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():                   <span class="comment"># disable gradient calculation</span></span><br><span class="line">            pred = model(x)                     <span class="comment"># forward pass (compute output)</span></span><br><span class="line">            mse_loss = model.cal_loss(pred, y)  <span class="comment"># compute loss</span></span><br><span class="line">        total_loss += mse_loss.detach().cpu().item() * <span class="built_in">len</span>(x)  <span class="comment"># accumulate loss</span></span><br><span class="line">    total_loss = total_loss / <span class="built_in">len</span>(dv_set.dataset)              <span class="comment"># compute averaged loss</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> total_loss</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">tt_set, model, device</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()                                <span class="comment"># set model to evalutation mode</span></span><br><span class="line">    preds = []</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> tt_set:                            <span class="comment"># iterate through the dataloader</span></span><br><span class="line">        x = x.to(device)                        <span class="comment"># move data to device (cpu/cuda)</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():                   <span class="comment"># disable gradient calculation</span></span><br><span class="line">            pred = model(x)                     <span class="comment"># forward pass (compute output)</span></span><br><span class="line">            preds.append(pred.detach().cpu())   <span class="comment"># collect prediction</span></span><br><span class="line">    preds = torch.cat(preds, dim=<span class="number">0</span>).numpy()     <span class="comment"># concatenate all predictions and convert to a numpy array</span></span><br><span class="line">    <span class="keyword">return</span> preds</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = get_device()                 <span class="comment"># get the current available device (&#x27;cpu&#x27; or &#x27;cuda&#x27;)</span></span><br><span class="line">os.makedirs(<span class="string">&#x27;models&#x27;</span>, exist_ok=<span class="literal">True</span>)  <span class="comment"># The trained model will be saved to ./models/</span></span><br><span class="line">target_only = <span class="literal">True</span>                   <span class="comment"># <span class="doctag">TODO:</span> Using 40 states &amp; 2 tested_positive features</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> How to tune these hyper-parameters to improve your model&#x27;s performance?</span></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&#x27;n_epochs&#x27;</span>: <span class="number">3000</span>,                <span class="comment"># maximum number of epochs</span></span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>: <span class="number">270</span>,               <span class="comment"># mini-batch size for dataloader</span></span><br><span class="line">    <span class="string">&#x27;optimizer&#x27;</span>: <span class="string">&#x27;SGD&#x27;</span>,              <span class="comment"># optimization algorithm (optimizer in torch.optim)</span></span><br><span class="line">    <span class="string">&#x27;optim_hparas&#x27;</span>: &#123;                <span class="comment"># hyper-parameters for the optimizer (depends on which optimizer you are using)</span></span><br><span class="line">        <span class="string">&#x27;lr&#x27;</span>: <span class="number">0.005</span>,                 <span class="comment"># learning rate of SGD</span></span><br><span class="line">        <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.5</span>              <span class="comment"># momentum for SGD</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&#x27;early_stop&#x27;</span>: <span class="number">200</span>,               <span class="comment"># early stopping epochs (the number epochs since your model&#x27;s last improvement)</span></span><br><span class="line">    <span class="string">&#x27;save_path&#x27;</span>: <span class="string">&#x27;models/model_select.path&#x27;</span>  <span class="comment"># your model will be saved here</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tr_set, tr_mu, tr_std = prep_dataloader(tr_path, <span class="string">&#x27;train&#x27;</span>, config[<span class="string">&#x27;batch_size&#x27;</span>], target_only=target_only)</span><br><span class="line">dv_set, mu_none, std_none = prep_dataloader(tr_path, <span class="string">&#x27;dev&#x27;</span>, config[<span class="string">&#x27;batch_size&#x27;</span>], target_only=target_only, mu=tr_mu, std=tr_std)</span><br><span class="line">tt_set, mu_none, std_none = prep_dataloader(tt_path, <span class="string">&#x27;test&#x27;</span>, config[<span class="string">&#x27;batch_size&#x27;</span>], target_only=target_only, mu=tr_mu, std=tr_std)</span><br></pre></td></tr></table></figure><pre><code>Finished reading the train set of COVID19 Dataset (1890 samples found, each dim = 54)
Finished reading the dev set of COVID19 Dataset (810 samples found, each dim = 54)
Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 54)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = NeuralNet(tr_set.dataset.dim).to(device)  <span class="comment"># Construct model and move to device</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>Saving model (epoch =    1, loss = 17.9400)
Saving model (epoch =    2, loss = 17.7633)
Saving model (epoch =    3, loss = 17.5787)
Saving model (epoch =    4, loss = 17.3771)
……
Saving model (epoch =  581, loss = 0.9606)
Saving model (epoch =  594, loss = 0.9606)
Saving model (epoch =  598, loss = 0.9606)
Saving model (epoch =  599, loss = 0.9604)
Saving model (epoch =  600, loss = 0.9603)
Saving model (epoch =  621, loss = 0.9602)
Saving model (epoch =  706, loss = 0.9601)
Saving model (epoch =  741, loss = 0.9601)
Saving model (epoch =  781, loss = 0.9598)
Saving model (epoch =  786, loss = 0.9597)
Finished training after 987 epochs
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plot_learning_curve(model_loss_record, title=<span class="string">&#x27;deep model&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://inews.gtimg.com/newsapp_ls/0/14146705610/0" alt="png"></p><p>​</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dev(dv_set, model, device)  <span class="comment">#验证集损失 </span></span><br></pre></td></tr></table></figure><pre><code>0.9599974950154623
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">del</span> model</span><br><span class="line">model = NeuralNet(tr_set.dataset.dim).to(device)</span><br><span class="line">ckpt = torch.load(config[<span class="string">&#x27;save_path&#x27;</span>], map_location=<span class="string">&#x27;cpu&#x27;</span>)  <span class="comment"># Load your best model</span></span><br><span class="line">model.load_state_dict(ckpt)</span><br><span class="line">plot_pred(dv_set, model, device)  <span class="comment"># Show prediction on the validation set</span></span><br></pre></td></tr></table></figure><p><img src="https://inews.gtimg.com/newsapp_ls/0/14146706545/0" alt="png"></p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_pred</span>(<span class="params">preds, file</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Save predictions to specified file &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Saving results to &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(file))</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        writer = csv.writer(fp)</span><br><span class="line">        writer.writerow([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;tested_positive&#x27;</span>])</span><br><span class="line">        <span class="keyword">for</span> i, p <span class="keyword">in</span> <span class="built_in">enumerate</span>(preds):</span><br><span class="line">            writer.writerow([i, p])</span><br><span class="line">preds = test(tt_set, model, device)  <span class="comment"># predict COVID-19 cases with your model</span></span><br><span class="line">save_pred(preds, <span class="string">&#x27;commit.csv&#x27;</span>)         <span class="comment"># save prediction file to pred.csv</span></span><br></pre></td></tr></table></figure><pre><code>Saving results to commit.csv
</code></pre><p>提交结果：</p><p><img src="https://inews.gtimg.com/newsapp_ls/0/14146709584/0"></p></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a></div><div class="post_share"><div class="social-share" data-image="https://inews.gtimg.com/newsapp_ls/0/14146721068/0" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/10/26/%E5%89%91%E6%8C%8753/"><img class="prev-cover" src="https://files.catbox.moe/jk4m9s.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">剑指 Offer 53 - I. 在排序数组中查找数字 I</div></div></a></div><div class="next-post pull-right"><a href="/2021/10/20/%E5%89%91%E6%8C%8703/"><img class="next-cover" src="https://files.catbox.moe/jk4m9s.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">剑指 Offer 03. 数组中重复的数字</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/09/28/2021-09-28-sklearn%E4%BD%BF%E7%94%A8%E5%87%BD%E6%95%B0%E6%96%87%E6%A1%A3/" title="sklearn使用函数文档"><img class="cover" src="https://files.catbox.moe/nqxbpk.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-28</div><div class="title">sklearn使用函数文档</div></div></a></div><div><a href="/2021/09/22/CNN/" title="CNN卷积神经网络笔记"><img class="cover" src="https://files.catbox.moe/rpfysi.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-22</div><div class="title">CNN卷积神经网络笔记</div></div></a></div><div><a href="/2021/08/28/C1/" title="MACHINE LEARNING"><img class="cover" src="https://files.catbox.moe/53u8pl.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-28</div><div class="title">MACHINE LEARNING</div></div></a></div><div><a href="/2021/09/26/K%E8%BF%91%E9%82%BB%20K-nearest%20neighbor/" title="K近邻 K-nearest neighbor"><img class="cover" src="https://files.catbox.moe/yechci.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-26</div><div class="title">K近邻 K-nearest neighbor</div></div></a></div><div><a href="/2021/11/01/self-attention(%E4%B8%8A)/" title="Self-attention(上)"><img class="cover" src="https://inews.gtimg.com/newsapp_ls/0/14141009653/0" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-01</div><div class="title">Self-attention(上)</div></div></a></div><div><a href="/2021/11/06/self-attention(%E4%B8%8B)/" title="Self-attention(下)"><img class="cover" src="https://inews.gtimg.com/newsapp_ls/0/14146047881/0" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-06</div><div class="title">Self-attention(下)</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/portrait.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">lijinhao</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">45</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">27</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/leekinghou"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/leekinghou" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:lijinhao716@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">醉后不知天在水，满船清梦压星河✨<div class="twopeople"><div class="twopeople"><div class="container" style="height:200px"><canvas class="illo" width="800" height="800" style="max-width:200px;max-height:200px;touch-action:none;width:640px;height:640px"></canvas></div><script src="https://cdn.guole.fun/js/twopeople1.js"></script><script src="https://cdn.guole.fun/js/zdog.dist.js"></script><script id="rendered-js" src="https://cdn.guole.fun/js/twopeople.js"></script><style>.twopeople{margin:0;align-items:center;justify-content:center;text-align:center}canvas{display:block;margin:0 auto;cursor:move}</style></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.</span> <span class="toc-text">下载数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.</span> <span class="toc-text">查看数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%8C%85"><span class="toc-number">3.</span> <span class="toc-text">导入包</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E5%B7%A5%E5%85%B7"><span class="toc-number">4.</span> <span class="toc-text">导入工具</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">5.</span> <span class="toc-text">预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">6.</span> <span class="toc-text">数据集</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By lijinhao</div><div class="framework-info"><span>Framework</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">满腔期待 常怀热情 有人等你<a target="_blank" rel="noopener" href="https://inews.gtimg.com/newsapp_ls/0/14146688226/0">Baikal♥️Swan</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">簡</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script>var preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",preloader.endLoading())</script><div class="js-pjax"></div><script defer id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zindex="-1" mobile="false" data-click="false"></script><script src="https://cdn-1.nesxc.com/js/smooth-scrolling.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script><script data-pjax>function GithubCalendarConfig(){var e=document.getElementById("recent-posts");e&&"/"==location.pathname&&(console.log("已挂载github calendar"),e.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>')),GithubCalendar("https://python-github-calendar-api.vercel.app/api?Leekinghou",["#ebedf0","#fdcdec","#fc9bd9","#fa6ac5","#f838b2","#f5089f","#c4067e","#92055e","#540336","#48022f","#30021f"],"Leekinghou")}document.getElementById("recent-posts")&&GithubCalendarConfig()</script><style>#github_container{min-height:280px}@media screen and (max-width:650px){#github_container{min-height:0}}</style><style></style></body></html>